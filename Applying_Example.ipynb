{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ba4861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA------------------------------------\n",
      "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "0             1000025                5                        1   \n",
      "1             1002945                5                        4   \n",
      "2             1015425                3                        1   \n",
      "3             1016277                6                        8   \n",
      "4             1017023                4                        1   \n",
      "\n",
      "   Uniformity of Cell Shape  Marginal Adhension  Single Epithelial Cell Size  \\\n",
      "0                         1                   1                            2   \n",
      "1                         4                   5                            7   \n",
      "2                         1                   1                            2   \n",
      "3                         8                   1                            3   \n",
      "4                         1                   3                            2   \n",
      "\n",
      "  Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
      "0           1                3                1        1      2  \n",
      "1          10                3                2        1      2  \n",
      "2           2                3                1        1      2  \n",
      "3           4                3                7        1      2  \n",
      "4           1                3                1        1      2  \n",
      "TOP 5 ACCURACY SCORE INFO------------------------------------\n",
      "    scaling_type             algorithm_name k_fold_parameter  \\\n",
      "225       minmax     decision_tree(entropy)  k_fold : 10 - 2   \n",
      "15          none     decision_tree(entropy)  k_fold : 10 - 2   \n",
      "120     standard     decision_tree(entropy)  k_fold : 10 - 2   \n",
      "74          none               logistic_reg  k_fold : 10 - 9   \n",
      "160     standard  decision_tree(gini_index)  k_fold : 10 - 7   \n",
      "\n",
      "    algorithm_parameter  accuracy_score  \n",
      "225      max_depth : 10        0.985507  \n",
      "15       max_depth : 10        0.985507  \n",
      "120      max_depth : 10        0.985507  \n",
      "74           C : 0.0001        0.985294  \n",
      "160      max_depth : 10        0.985294  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "#kfold\n",
    "from sklearn.model_selection import KFold\n",
    "#model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "#score\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "#load data\n",
    "colnames = ['Sample code number','Clump Thickness','Uniformity of Cell Size'\n",
    "            ,'Uniformity of Cell Shape','Marginal Adhension','Single Epithelial Cell Size'\n",
    "            ,'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', names = colnames)\n",
    "print('DATA------------------------------------')\n",
    "print(data.head(5))\n",
    "\n",
    "#dirty data cleaning\n",
    "#drop all Missing attribute values(? -> null -> drop)\n",
    "data = data.replace('?', None)\n",
    "data = data.dropna(axis = 0)\n",
    "\n",
    "#feature engineering\n",
    "#drop 'Sample code number' column\n",
    "data.drop(['Sample code number'], axis = 1, inplace = True)\n",
    "\n",
    "#change target 2 > 0, 4 > 1\n",
    "data['Class'] = data['Class'].replace(2,0)\n",
    "data['Class'] = data['Class'].replace(4,1)\n",
    "\n",
    "#divide dataset to non_target and target\n",
    "dataset_non_target = data.drop(['Class'], axis = 1, inplace = False)\n",
    "dataset_target = pd.DataFrame(data['Class'], columns = ['Class'])\n",
    "\n",
    "#function ML : do dataset scaling, make model, calculate accuracy score and return that info using dataframe form\n",
    "# input : scaling_type, algorithm_name, dataset_no_target, dataset_target\n",
    "# output : function_reusult_dataframe\n",
    "def ML(scaling_type, algorithm_name, dataset_no_target, dataset_target):\n",
    "    function_result_df = pd.DataFrame(columns = ['scaling_type','algorithm_name','k_fold_parameter','algorithm_parameter','accuracy_score'])\n",
    "    function_result_cnt = 0\n",
    "    #do scaling using scaling type\n",
    "    scaler = None\n",
    "    scaled_data = dataset_no_target\n",
    "    \n",
    "    # 3 type of scaling : none, standard, minmax\n",
    "    if scaling_type == 'none':\n",
    "        pass #do nothing\n",
    "    elif scaling_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        print('ERROR : scaling type error')\n",
    "        return\n",
    "    \n",
    "    if scaler != None:\n",
    "        scaled_data = scaler.fit_transform(dataset_no_target)\n",
    "    dataset_no_target = pd.DataFrame(scaled_data, columns = dataset_no_target.columns)\n",
    "    \n",
    "    #do k-fold\n",
    "    for k_fold_param in [5,10]:#k_fold_parameter : 5,10\n",
    "        kfold = KFold(n_splits = k_fold_param)\n",
    "        k_fold_num = 0\n",
    "        for train_index, test_index in kfold.split(dataset_no_target):\n",
    "            x_train, x_test = dataset_no_target.iloc[train_index,:], dataset_no_target.iloc[test_index,:]\n",
    "            y_train, y_test = dataset_target.iloc[train_index,:], dataset_target.iloc[test_index,:]\n",
    "            \n",
    "            #4 type of model : ['decision_tree(entropy)','decision_tree(gini_index)','logistic_reg','svm']\n",
    "            if algorithm_name == 'decision_tree(entropy)':\n",
    "                for max_depth_param in [1, 10]: #max_depth_param 1, 10\n",
    "                    model = DecisionTreeClassifier(criterion = 'entropy', max_depth = max_depth_param, random_state = 1)\n",
    "                    model.fit(x_train,y_train)\n",
    "                    pred = model.predict(x_test)\n",
    "                    accuracy = model.score(x_test,y_test)\n",
    "                    \n",
    "                    k_fold_param_str = 'k_fold : {} - {}'.format(str(k_fold_param), str(k_fold_num))\n",
    "                    algorithm_param = 'max_depth : {}'.format(str(max_depth_param))\n",
    "                    result_list = make_result_list(scaling_type, algorithm_name, k_fold_param_str, algorithm_param, accuracy)\n",
    "                    function_result_df.loc[function_result_cnt]=result_list\n",
    "                    function_result_cnt = function_result_cnt + 1\n",
    "            elif algorithm_name == 'decision_tree(gini_index)':\n",
    "                for max_depth_param in [1, 10]: #max_depth_param 1, 10\n",
    "                    model = DecisionTreeClassifier(criterion = 'gini', max_depth = max_depth_param, random_state = 1)\n",
    "                    model.fit(x_train,y_train)\n",
    "                    pred = model.predict(x_test)\n",
    "                    accuracy = model.score(x_test,y_test)\n",
    "                    \n",
    "                    k_fold_param_str = 'k_fold : {} - {}'.format(str(k_fold_param), str(k_fold_num))\n",
    "                    algorithm_param = 'max_depth : {}'.format(str(max_depth_param))\n",
    "                    result_list = make_result_list(scaling_type, algorithm_name, k_fold_param_str, algorithm_param, accuracy)\n",
    "                    function_result_df.loc[function_result_cnt]=result_list\n",
    "                    function_result_cnt = function_result_cnt + 1\n",
    "            elif algorithm_name == 'logistic_reg':\n",
    "                for C_param in  [0.0001]: #C parameter : 0.0001\n",
    "                    model = LogisticRegression(solver = 'lbfgs', C = C_param)\n",
    "                    model.fit(x_train,y_train.values.ravel())\n",
    "                    pred = model.predict(x_test)\n",
    "                    accuracy = model.score(x_test,y_test)\n",
    "                    \n",
    "                    k_fold_param_str = 'k_fold : {} - {}'.format(str(k_fold_param), str(k_fold_num))\n",
    "                    algorithm_param = 'C : {}'.format(str(C_param))\n",
    "                    #algorithm_param = 'none'\n",
    "                    result_list = make_result_list(scaling_type, algorithm_name, k_fold_param_str, algorithm_param, accuracy)\n",
    "                    function_result_df.loc[function_result_cnt]=result_list\n",
    "                    function_result_cnt = function_result_cnt + 1\n",
    "            elif algorithm_name == 'svm':\n",
    "                for kernel_name in ['rbf']:#kernel_name #['linear','rbf']\n",
    "                      #kernel_name == 'rbf'\n",
    "                    for C_param in  [0.0001, 0.001]: #C parameter : 0.0001 0.001\n",
    "                        model = SVC(kernel = 'rbf', C = C_param, random_state = 1)\n",
    "                        model.fit(x_train,y_train.values.ravel())\n",
    "                        pred = model.predict(x_test)\n",
    "                        accuracy = model.score(x_test,y_test)\n",
    "                                \n",
    "                        k_fold_param_str = 'k_fold : {} - {}'.format(str(k_fold_param), str(k_fold_num))\n",
    "                        algorithm_param = 'kernel : {}, C: {}'.format(str(kernel_name),str(C_param))\n",
    "                        result_list = make_result_list(scaling_type, algorithm_name, k_fold_param_str, algorithm_param, accuracy)\n",
    "                        function_result_df.loc[function_result_cnt]=result_list\n",
    "                        function_result_cnt = function_result_cnt + 1               \n",
    "            else:\n",
    "                print('ERROR : algorithm name error')\n",
    "                return\n",
    "            k_fold_num = k_fold_num + 1\n",
    "        \n",
    "    return function_result_df\n",
    "#function make_result_list : make one line(list) of function ML's return dataframe\n",
    "# input : scaling_type, algorithm_name, k_fold_param, algorithm_param, accuracy\n",
    "# output : result_list\n",
    "def make_result_list(scaling_type, algorithm_name, k_fold_param, algorithm_param, accuracy):\n",
    "    result_list = []\n",
    "    result_list.append(scaling_type)\n",
    "    result_list.append(algorithm_name)\n",
    "    result_list.append(k_fold_param)\n",
    "    result_list.append(algorithm_param)\n",
    "    result_list.append(accuracy)\n",
    "    return result_list\n",
    "\n",
    "#make list to store all type of scaling or algorithm\n",
    "algorithm_list = ['decision_tree(entropy)','decision_tree(gini_index)','logistic_reg','svm']\n",
    "scaling_type = ['none','standard','minmax']\n",
    "\n",
    "#make dataframe to store all result\n",
    "result = pd.DataFrame(columns = ['scaling_type','algorithm_name','k_fold_parameter','algorithm_parameter','accuracy_score'])\n",
    "\n",
    "for scaling_name in scaling_type:\n",
    "    for algorithm_name in algorithm_list:\n",
    "        temp_result = ML(scaling_name, algorithm_name, dataset_non_target, dataset_target)\n",
    "        result = pd.concat([result, temp_result], ignore_index = True)\n",
    "\n",
    "\n",
    "#sorted result and find best accuracy score cases\n",
    "result_sorted = result.sort_values(by = ['accuracy_score'], ascending = False)\n",
    "print('TOP 5 ACCURACY SCORE INFO------------------------------------')\n",
    "print(result_sorted.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92bfdd1",
   "metadata": {},
   "source": [
    "## - Result Analysis\n",
    "Among the TOP 5 accuracy scores,\n",
    "the scaling type has a distribution of standard(2), none(2), and minmax(1),\n",
    "the algorithm name has a distribution of decision_tree(entropy) (3), logistic_regression(1), and decision_tree(gini_index)(1),\n",
    "and k_fold_parameter has a distribution of 10(5).\n",
    "In particular, TOP1 ~ 3, all had different scaling_type, but they all had the same accuracy score as model = decision_tree(entropy)(max_depth = 10), k(in k-fold hyperparameter) = 10.\n",
    "Therefore, which model was used had the most influence on accuracy than scaling type and k_fold_parameter.\n",
    "It is appropriate to satisfy the conditions of TOP1-TOP3 case(model = decision_tree(entropy)(max_depth = 10), k(in k-fold hyperparameter) = 10) to derive the best accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951091b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
